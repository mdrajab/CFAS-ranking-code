{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Import required packages & functions <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing libraries')\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# clear all variables\n",
    "for i in list(globals().keys()):\n",
    "    if(i[0] != '_'):\n",
    "        exec('del {}'.format(i))\n",
    "\n",
    "#suppress future warnings -- not really a good idea \n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import required dependencies\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, silhouette_score\n",
    "import csv\n",
    "import xlrd\n",
    "import math\n",
    "from matplotlib import figure\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#import utils\n",
    "#from utils import encode_features_v3\n",
    "\n",
    "set_matplotlib_formats('png', 'pdf') # uses vector figures in pdf exports --\n",
    "plt.style.use('seaborn-pastel')\n",
    "\n",
    "# create a folder\n",
    "def create_folder(folder):\n",
    "    import os     \n",
    "    try: \n",
    "        os.mkdir(folder) \n",
    "    except FileExistsError:\n",
    "        print(\"Directory [ %s ] already exists\"%folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Load data   <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(\"Misclassified\")\n",
    "\n",
    "dataset = pd.read_csv('Classification/new_balanced_no_AB.csv');\n",
    "dataset = dataset.drop(columns=['Case'])\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = np.ravel(dataset.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Function to predict for all classifiers   <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_fscore_mean=[]; logreg_precision_mean=[]; logreg_recall_mean=[]; logreg_balanced_acc_mean=[]\n",
    "logreg_sens_mean=[]; logreg_spec_mean=[]; logreg_acc_mean=[]; \n",
    "logreg_average_precision_mean=[]; logreg_auc_mean=[];\n",
    "\n",
    "dt_fscore_mean=[]; dt_precision_mean=[]; dt_recall_mean=[]; dt_balanced_acc_mean=[]\n",
    "dt_sens_mean=[]; dt_spec_mean=[]; dt_acc_mean=[]; \n",
    "dt_average_precision_mean=[]; dt_auc_mean=[]\n",
    "\n",
    "knn_fscore_mean=[]; knn_precision_mean=[]; knn_recall_mean=[]; knn_balanced_acc_mean=[]\n",
    "knn_sens_mean=[]; knn_spec_mean=[]; knn_acc_mean=[]; \n",
    "knn_average_precision_mean=[]; knn_auc_mean=[]\n",
    "\n",
    "lda_fscore_mean=[]; lda_precision_mean=[]; lda_recall_mean=[]; lda_balanced_acc_mean=[]\n",
    "lda_sens_mean=[]; lda_spec_mean=[]; lda_acc_mean=[]; \n",
    "lda_average_precision_mean=[]; lda_auc_mean=[]\n",
    "\n",
    "gnb_fscore_mean=[]; gnb_precision_mean=[]; gnb_recall_mean=[]; gnb_balanced_acc_mean=[]\n",
    "gnb_sens_mean=[]; gnb_spec_mean=[]; gnb_acc_mean=[]; \n",
    "gnb_average_precision_mean=[]; gnb_auc_mean=[]\n",
    "\n",
    "svm_rbf_fscore_mean=[]; svm_rbf_precision_mean=[]; svm_rbf_recall_mean=[]; svm_rbf_balanced_acc_mean=[] \n",
    "svm_rbf_sens_mean=[]; svm_rbf_spec_mean=[]; svm_rbf_acc_mean=[]; \n",
    "svm_rbf_average_precision_mean=[]; svm_rbf_auc_mean=[]\n",
    "\n",
    "svm_linear_fscore_mean=[]; svm_linear_precision_mean=[]; svm_linear_recall_mean=[]; svm_linear_balanced_acc_mean=[] \n",
    "svm_linear_sens_mean=[]; svm_linear_spec_mean=[]; svm_linear_acc_mean=[];\n",
    "svm_linear_average_precision_mean=[]; svm_linear_auc_mean=[];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_pred = pd.DataFrame()\n",
    "\n",
    "logreg_y_pred = pd.DataFrame(); dt_y_pred = pd.DataFrame(); knn_y_pred = pd.DataFrame(); lda_y_pred = pd.DataFrame();\n",
    "gnb_y_pred = pd.DataFrame(); svm_rbf_y_pred = pd.DataFrame(); svm_linear_y_pred = pd.DataFrame();\n",
    "\n",
    "# create loocv procedure\n",
    "cv = LeaveOneOut()\n",
    "print(\"subset:\")\n",
    "for num in range(0,22):\n",
    "    print(num,\" \\b\", end=\"\")\n",
    "    \n",
    "    #get data and target\n",
    "    X_subset = X.iloc[:,num::-1]\n",
    "    \n",
    "    # feature scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_subset)\n",
    "    \n",
    "    logreg = LogisticRegression(random_state = 220)\n",
    "    dt = DecisionTreeClassifier(random_state = 220)\n",
    "    knn = KNeighborsClassifier()\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    gnb = GaussianNB()\n",
    "    svm_rbf = SVC(kernel='rbf', random_state = 220)\n",
    "    svm_linear = SVC(kernel='linear', random_state = 220)\n",
    "    \n",
    "    # calculate cross validation score for each of the fitted models \n",
    "    for model in ['logreg', 'dt', 'knn', 'lda', 'gnb', 'svm_rbf', 'svm_linear']:   \n",
    "        # enumerate splits\n",
    "        y_true, y_pred = list(), list()\n",
    "        for train_ix, test_ix in cv.split(X_scaled):\n",
    "            # split data\n",
    "            X_train, X_test = X_scaled[train_ix, :], X_scaled[test_ix, :]\n",
    "            y_train, y_test = y[train_ix], y[test_ix]\n",
    "            # fit model\n",
    "            exec(\"%s\"%model+\".fit(X_train, y_train)\")\n",
    "            # evaluate model\n",
    "            exec(\"yhat = %s\"%model+\".predict(X_test)\")\n",
    "            # store\n",
    "            y_true.append(y_test[0])\n",
    "            y_pred.append(yhat[0])\n",
    "        exec(\"%s\"%model+\"_y_pred['%s\"%model+\"_%d\"%(num+1)+\"'] = y_pred\")\n",
    "        \n",
    "        exec(\"%s\"%model+\"_fscore_mean.append(f1_score(y, y_pred))\") \n",
    "        exec(\"%s\"%model+\"_precision_mean.append(precision_score(y, y_pred))\")\n",
    "        exec(\"%s\"%model+\"_recall_mean.append(recall_score(y, y_pred))\")\n",
    "        exec(\"%s\"%model+\"_balanced_acc_mean.append(balanced_accuracy_score(y, y_pred))\")\n",
    "        exec(\"%s\"%model+\"_acc_mean.append(accuracy_score(y, y_pred))\")\n",
    "        exec(\"%s\"%model+\"_average_precision_mean.append(average_precision_score(y, y_pred))\")\n",
    "#         exec(\"sens, spec, auc_value = perf_eval(y, y_pred)\")\n",
    "#         exec(\"%s\"%model+\"_sens_mean.append(sens)\") \n",
    "#         exec(\"%s\"%model+\"_spec_mean.append(spec)\") \n",
    "#         exec(\"%s\"%model+\"_auc_mean.append(auc_value)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Binary Table Matrix   <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame()\n",
    "all_y_pred = pd.DataFrame()\n",
    "for model in ['logreg', 'dt', 'knn', 'lda', 'gnb', 'svm_rbf', 'svm_linear']:\n",
    "    exec(\"all_y_pred = pd.concat([all_y_pred, %s\"%model+\"_y_pred], axis=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ FUNCTION -----------------------#\n",
    "def binary_table(y_pred, y_true):\n",
    "    data = pd.DataFrame(y_pred)\n",
    "    data['y_true'] = y_true['dem_nver4']\n",
    "\n",
    "    cond_1 = (data.iloc[:,1] == 1) & (data.iloc[:,0] == 1)\n",
    "    cond_2 = (data.iloc[:,1] == 0) & (data.iloc[:,0] == 0)\n",
    "    cond_3 = (data.iloc[:,1] == 1) & (data.iloc[:,0] != 1)\n",
    "    cond_4 = (data.iloc[:,1] == 0) & (data.iloc[:,0] != 0)\n",
    "\n",
    "    conditions = [cond_1,cond_2,cond_3,cond_4]\n",
    "#     choices = [0,0,1,-1]\n",
    "    choices = [0,0,1,-1]\n",
    "\n",
    "    data.drop('y_true', axis=1, inplace=True)\n",
    "    data.iloc[:,0] = np.select(conditions, choices, default='null')\n",
    "    return data\n",
    "#---------------------------------------------------#\n",
    "\n",
    "X = pd.DataFrame(dataset.iloc[:,:-1])\n",
    "y = pd.DataFrame(dataset.dem_nver4)\n",
    "\n",
    "all_binary_result = pd.DataFrame(y)\n",
    "\n",
    "for classifier in ['logreg','dt','knn','lda','gnb','svm_rbf','svm_linear']:\n",
    "    for subset in np.arange(1, 23, 1):\n",
    "        exec(\"%s\"%classifier+\"_%s\"%subset+\" = binary_table(all_y_pred['%s\"%classifier+\"_%s\"%subset+\"'],y)\")\n",
    "        exec(\"all_binary_result['%s\"%classifier+\"_%s\"%subset+\"'] = %s\"%classifier+\"_%s\"%subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import table \n",
    "all_binary_result.drop('dem_nver4', axis=1,inplace=True)\n",
    "\n",
    "aa = all_binary_result.style.applymap(lambda x: \"background-color: red\" if x == '-1' else \"background-color: blue\" if x == '1' else \"background-color: white\")\n",
    "\n",
    "all_binary_result = all_binary_result.astype(int)\n",
    "aaa_test = all_binary_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Hierarchical Clustering   <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage ='average')\n",
    "\n",
    "y_hc=hc.fit(all_binary_result)\n",
    "\n",
    "#get rows' clusters\n",
    "membership = hc.labels_\n",
    "binary_clusters = pd.DataFrame(all_binary_result).copy()\n",
    "binary_clusters['clusters'] = membership\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(14, 10)) \n",
    "dendrogram = sch.dendrogram(sch.linkage(all_binary_result, method  = \"average\"))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Samples/Patients')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.axhline(y=14, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save membership to csv file for clinical signatures\n",
    "membership_value = pd.DataFrame()\n",
    "membership_value['membership'] = membership\n",
    "membership_value.to_csv(r'Classification/membership_value.csv', index=False, mode = 'w')\n",
    "\n",
    "\n",
    "dataset_membership = pd.read_csv('Classification/new_balanced_no_AB.csv');\n",
    "dataset_membership = dataset_membership.drop(columns=['Case'])\n",
    "dataset_membership['membership'] = membership\n",
    "dataset_membership.to_csv(r'Classification/dataset_membership.csv', index=False, mode = 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "heatmap_binary = all_binary_result\n",
    "heatmap_binary.columns = pd.MultiIndex.from_product([['logreg', 'dt', 'knn', 'lda', 'gnb', 'svm_rbf', 'svm_linear'], \n",
    "                                                     np.arange(1, 23, 1)], \n",
    "                                                   names=['Classifiers', 'Subsets of Features'])\n",
    "# ### For tree colors\n",
    "clusters = binary_clusters.pop(\"clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [0 - FN - 22] [1 - FP - 24] [2 - TP&TN - 68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Cluster Heatmap  <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "#### classifiers level\n",
    "classi_labels = heatmap_binary.columns.get_level_values(\"Classifiers\")\n",
    "classi_pal = sns.cubehelix_palette(classi_labels.unique().size, light=.9, dark=.1, reverse=True, start=1, rot=-2)\n",
    "classi_lut = dict(zip(map(str, classi_labels.unique()), classi_pal))\n",
    "\n",
    "#### Create index using the columns for classifiers\n",
    "classi_colors = pd.Series(classi_labels, index=heatmap_binary.columns).map(classi_lut)\n",
    "\n",
    "#### subsets level\n",
    "subset_labels = heatmap_binary.columns.get_level_values(\"Subsets of Features\")\n",
    "subset_pal = sns.cubehelix_palette(subset_labels.unique().size, as_cmap=True, hue=0, start=0.3, light=1.0, dark=0.0,rot=-10.0, gamma=10.0)\n",
    "\n",
    "#### Create index using the columns for subsets\n",
    "subset_colors = pd.Series(subset_labels, index=heatmap_binary.columns).map(subset_pal)\n",
    "\n",
    "# classi_subset_colors = pd.DataFrame(subset_colors)\n",
    "classi_subset_colors = pd.DataFrame(subset_colors)#pd.DataFrame(classi_colors).join(pd.DataFrame(subset_colors))\n",
    "\n",
    "### decoding colors for heatmap and dendograms\n",
    "red=(0.5, 0.0, 0.0, 1.0)\n",
    "blue=(0.0, 0.0, 0.5, 1.0)\n",
    "black=(0.0, 0.0, 0.0, 0.0)\n",
    "white=(1,1,1,1)\n",
    "grey=(0.5, 0.5, 0.5, 1.0)\n",
    "\n",
    "### tree clusters colors\n",
    "\n",
    "clusters_lut = dict(zip(clusters.unique(), [grey, red, blue]))\n",
    "row_colors = clusters.map(clusters_lut)\n",
    "# df_colors = pd.DataFrame(data={'False Positive [18 Individuals]': row_colors[row_colors == blue], 'False Negative [22 Individuals]': row_colors[row_colors == red], 'Correctly Classified [62 Individuals]': row_colors[row_colors == grey]})\n",
    "\n",
    "''''''''''''''''''\n",
    "plt.rc('font', size=14)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=14)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('ytick', labelsize=4)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize\n",
    "plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "\n",
    "plt.rcParams['savefig.facecolor']='white'\n",
    "\n",
    "myColors = (blue,black, red)\n",
    "cmap = LinearSegmentedColormap.from_list('Custom', myColors, len(myColors))\n",
    "\n",
    "\n",
    "# color bar keyword arguments\n",
    "cbar_kws = {\"shrink\":1,\n",
    "            'ticks': ['f',0,-1], # set ticks of color bar\n",
    "            'label':'Color Bar'}\n",
    "\n",
    "g = sns.clustermap(all_binary_result,\n",
    "                    method= 'average',\n",
    "                    metric= \"euclidean\",\n",
    "                    col_cluster=False,\n",
    "                    row_cluster=True,\n",
    "                    col_colors = classi_subset_colors,\n",
    "                    row_colors=row_colors,\n",
    "                    cmap=cmap,\n",
    "                    tree_kws=dict(linewidths=0.95, colors=([red]*21+[blue]*23+[grey]*67+[(0,0,0,1)]*2)),\n",
    "                    linewidths=0.0,\n",
    "                   rasterized=True,\n",
    "                   xticklabels=False, \n",
    "                   yticklabels=False, \n",
    "                   center=0) \n",
    "\n",
    "g.cax.set_visible(False)\n",
    "g.ax_row_dendrogram.set_visible(True)\n",
    "g.ax_col_dendrogram.set_visible(True)\n",
    "\n",
    "ax = g.ax_heatmap\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Individuals\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "g.savefig('Figures/all_subsets_clustermap.pdf',dpi=300, bbox_inches=\"tight\")\n",
    "g.savefig('Figures/all_subsets_clustermap.png',dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Prepare Clinical Features for Signature  <a class=\"anchor\" id=\"chapter7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('../data/master.csv',header = 0)\n",
    "clinical_features = pd.read_csv('../data/clinical features.csv',header = 0)\n",
    "\n",
    "aa = pd.read_csv('Classification/dataset_membership.csv')\n",
    "\n",
    "new_balanced_no_AB = pd.read_csv('Classification/new_balanced_no_AB.csv')\n",
    "selected_clinical = new_balanced_no_AB.iloc[:,0:1].merge(master[clinical_features.feature], how = 'inner', on = ['Case'])\n",
    "selected_clinical\n",
    "\n",
    "''' Adjusment of brain weight based on gender '''\n",
    "women_braiwgt = selected_clinical[selected_clinical.sex == 'Women']\n",
    "men_braiwgt = selected_clinical[selected_clinical.sex == 'Men']\n",
    "gender_missing = selected_clinical[selected_clinical.sex.isnull()]\n",
    "\n",
    "#Calculate z-score by mean\n",
    "from scipy import stats\n",
    "women_braiwgt_zscore = stats.zscore(women_braiwgt['brain weight'], nan_policy='omit')\n",
    "men_braiwgt_zscore = stats.zscore(men_braiwgt['brain weight'], nan_policy='omit')\n",
    "women_braiwgt['brain weight'] = women_braiwgt_zscore\n",
    "men_braiwgt['brain weight'] = men_braiwgt_zscore\n",
    "\n",
    "selected_clinical = pd.concat([women_braiwgt, men_braiwgt])\n",
    "selected_clinical = pd.concat([selected_clinical, gender_missing])\n",
    "selected_clinical.sort_values(by='Case', inplace=True)\n",
    "\n",
    "membership_value = pd.read_csv('Classification/membership_value.csv',header = 0) # read clinical dataset\n",
    "selected_clinical['membership_value'] = membership_value.membership.copy()\n",
    "values = pd.DataFrame(membership_value.membership).copy()\n",
    "selected_clinical['membership'] = values.membership.replace({0:'TP&TN', 1:'FN', 2:'FP'})\n",
    "\n",
    "'''\n",
    "        This file is used for clinical signatures by (https://github.com/emmanueljammeh/cfas)\n",
    "        \n",
    "'''\n",
    "selected_clinical.to_csv(r'Classification/clinical_with_memberships.csv',mode = 'w',index=False)\n",
    "\n",
    "selected_clinical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Clinical Signature Figure  <a class=\"anchor\" id=\"chapter8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Emmanuel A. Jammeh code results, the file shows the features with their coefficient values that are having association with the three clusters (FP, FN, and TP&TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_singnature = pd.read_csv('../data/relevant_clinical_signatures_coefficients.csv',header = 0)\n",
    "clinical_singnature['Sum'] = clinical_singnature.iloc[:,2:5].abs().sum(axis=1)\n",
    "clinical_singnature.sort_values(by='Sum', inplace=True, ascending=False)\n",
    "clinical_singnature\n",
    "\n",
    "red=(0.5, 0.0, 0.0, 1.0)\n",
    "blue=(0.0, 0.0, 0.5, 1.0)\n",
    "grey=(0.5, 0.5, 0.5, 1.0)\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "# plt.subplots_adjust(wspace=0.10)\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "size = 16\n",
    "plt.rc('font', size=size)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=size)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=size)    # fontsize of the x and y labels\n",
    "plt.rc('ytick', labelsize=size)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=size)    # legend fontsize\n",
    "plt.rc('xtick', labelsize=size)    # fontsize of the tick labels\n",
    "ax = plt.subplot(3,1,1)\n",
    "ax.bar(clinical_singnature.features, clinical_singnature.Cluster1, width=0.7, color=red)\n",
    "ax.axhline(y=0, color='k')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xticks(' ')\n",
    "plt.title('False Negative')\n",
    "plt.ylim(-1, 1,0.25)\n",
    "plt.tight_layout()\n",
    "\n",
    "ax = plt.subplot(3,1,2)\n",
    "ax.bar(clinical_singnature.features, clinical_singnature.Cluster2, width=0.7, color=blue)\n",
    "ax.axhline(y=0, color='k')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xticks(' ')\n",
    "plt.title('False Positive')\n",
    "plt.ylim(-1, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "ax = plt.subplot(3,1,3)\n",
    "ax.bar(clinical_singnature.features, clinical_singnature.Cluster0, width=0.7, color=grey)\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Correctly Classified')\n",
    "ax.axhline(y=0, color='k')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45, horizontalalignment=\"right\")\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.savefig('Figures/clinical_signature.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('Figures/clinical_signature.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
